{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks\n",
    "\n",
    "For this part of the assignment you implement two different types of generative adversarial networks. We will train the networks on the Celeb A dataset which is a large set of celebrity face images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 805,
     "status": "ok",
     "timestamp": 1541617322541,
     "user": {
      "displayName": "Daniel McKee",
      "photoUrl": "",
      "userId": "05833574158187352909"
     },
     "user_tz": 360
    },
    "id": "QRNx4wtGvPYR",
    "outputId": "2f26829c-4533-432c-b698-d645e512eee4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-710Hh-8-nti"
   },
   "outputs": [],
   "source": [
    "from gan.train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will implement two different types of GAN cost functions. You will first implement the loss from the [original GAN paper](https://arxiv.org/pdf/1406.2661.pdf). You will also implement the loss from [LS-GAN](https://arxiv.org/abs/1611.04076). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QOVWxdbK-nuI"
   },
   "source": [
    "### GAN loss\n",
    "\n",
    "**TODO:** Implement the `discriminator_loss` and `generator_loss` functions in `gan/losses.py`.\n",
    "\n",
    "The generator loss is given by:\n",
    "$$\\ell_G  =  -\\mathbb{E}_{z \\sim p(z)}\\left[\\log D(G(z))\\right]$$\n",
    "and the discriminator loss is:\n",
    "$$ \\ell_D = -\\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\log D(x)\\right] - \\mathbb{E}_{z \\sim p(z)}\\left[\\log \\left(1-D(G(z))\\right)\\right]$$\n",
    "Note that these are negated from the equations presented earlier as we will be *minimizing* these losses.\n",
    "\n",
    "**HINTS**: You should use the `torch.nn.functional.binary_cross_entropy_with_logits` function to compute the binary cross entropy loss since it is more numerically stable than using a softmax followed by BCE loss. The BCE loss is needed to compute the log probability of the true label given the logits output from the discriminator. Given a score $s\\in\\mathbb{R}$ and a label $y\\in\\{0, 1\\}$, the binary cross entropy loss is\n",
    "\n",
    "$$ bce(s, y) = -y * \\log(s) - (1 - y) * \\log(1 - s) $$\n",
    "\n",
    "\n",
    "Instead of computing the expectation of $\\log D(G(z))$, $\\log D(x)$ and $\\log \\left(1-D(G(z))\\right)$, we will be averaging over elements of the minibatch, so make sure to combine the loss by averaging instead of summing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gan.losses import discriminator_loss, generator_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RXfoe96P-nud"
   },
   "source": [
    "### Least Squares GAN loss\n",
    "\n",
    "**TODO:** Implement the `ls_discriminator_loss` and `ls_generator_loss` functions in `gan/losses.py`.\n",
    "\n",
    "We'll now look at [Least Squares GAN](https://arxiv.org/abs/1611.04076), a newer, more stable alernative to the original GAN loss function. For this part, all we have to do is change the loss function and retrain the model. We'll implement equation (9) in the paper, with the generator loss:\n",
    "$$\\ell_G  =  \\frac{1}{2}\\mathbb{E}_{z \\sim p(z)}\\left[\\left(D(G(z))-1\\right)^2\\right]$$\n",
    "and the discriminator loss:\n",
    "$$ \\ell_D = \\frac{1}{2}\\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\left(D(x)-1\\right)^2\\right] + \\frac{1}{2}\\mathbb{E}_{z \\sim p(z)}\\left[ \\left(D(G(z))\\right)^2\\right]$$\n",
    "\n",
    "\n",
    "**HINTS**: Instead of computing the expectation, we will be averaging over elements of the minibatch, so make sure to combine the loss by averaging instead of summing. When plugging in for $D(x)$ and $D(G(z))$ use the direct output from the discriminator (`scores_real` and `scores_fake`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gan.losses import ls_discriminator_loss, ls_generator_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN model architecture\n",
    "\n",
    "**TODO:** Implement the `Discriminator` and `Generator` networks in `gan/models.py`.\n",
    "\n",
    "We recommend the following architectures which are inspired by [DCGAN](https://arxiv.org/pdf/1511.06434.pdf):\n",
    "\n",
    "**Discriminator:**\n",
    "\n",
    "- convolutional layer with in_channels=3, out_channels=128, kernel=4, stride=2\n",
    "- convolutional layer with in_channels=128, out_channels=256, kernel=4, stride=2\n",
    "- batch norm\n",
    "- convolutional layer with in_channels=256, out_channels=512, kernel=4, stride=2\n",
    "- batch norm\n",
    "- convolutional layer with in_channels=512, out_channels=1024, kernel=4, stride=2\n",
    "- batch norm\n",
    "- convolutional layer with in_channels=1024, out_channels=1, kernel=4, stride=1\n",
    "\n",
    "Instead of Relu we LeakyReLu throughout the discriminator (we use a negative slope value of 0.2). \n",
    "\n",
    "The output of your discriminator should be a single value score corresponding to each input sample. See `torch.nn.LeakyReLU`.\n",
    "\n",
    "\n",
    "**Generator:**\n",
    "\n",
    "**Note:** In the generator, you will need to use transposed convolution (sometimes known as fractionally-strided convolution or deconvolution). This function is implemented in pytorch as `torch.nn.ConvTranspose2d`.\n",
    "\n",
    "- transpose convolution with in_channels=NOISE_DIM, out_channels=1024, kernel=4, stride=1\n",
    "- batch norm\n",
    "- transpose convolution with in_channels=1024, out_channels=512, kernel=4, stride=2\n",
    "- batch norm\n",
    "- transpose convolution with in_channels=512, out_channels=256, kernel=4, stride=2\n",
    "- batch norm\n",
    "- transpose convolution with in_channels=256, out_channels=128, kernel=4, stride=2\n",
    "- batch norm\n",
    "- transpose convolution with in_channels=128, out_channels=3, kernel=4, stride=2\n",
    "\n",
    "The output of the final layer of the generator network should have a `tanh` nonlinearity to output values between -1 and 1. The output should be a 3x64x64 tensor for each sample (equal dimensions to the images from the dataset).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gan.models import Discriminator, Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_sgpDWlbM90t"
   },
   "source": [
    "# Data loading: Celeb A Dataset\n",
    "\n",
    "The CelebA images we provide have been filtered to obtain only images with clear faces and have been cropped and downsampled to 128x128 resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "scale_size = 64  # We resize the images to 64x64 for training\n",
    "\n",
    "celeba_root = 'celeba_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a6IzyDdZM9bp"
   },
   "outputs": [],
   "source": [
    "celeba_train = ImageFolder(root=celeba_root, transform=transforms.Compose([\n",
    "  transforms.Resize(scale_size),\n",
    "  transforms.ToTensor(),\n",
    "]))\n",
    "\n",
    "celeba_loader_train = DataLoader(celeba_train, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12368,
     "status": "ok",
     "timestamp": 1541578338354,
     "user": {
      "displayName": "Daniel McKee",
      "photoUrl": "",
      "userId": "05833574158187352909"
     },
     "user_tz": 360
    },
    "id": "uiThPjUSwc3P",
    "outputId": "ee3c69cf-e5f2-43c1-9fcc-46cdb650bec1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgs = celeba_loader_train.__iter__().next()[0].numpy().squeeze()\n",
    "show_images(imgs, color=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training \n",
    "\n",
    "\n",
    "**TODO:** Fill in the training loop in `gan/train.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_DIM = 100\n",
    "NUM_EPOCHS = 50\n",
    "learning_rate = 0.0002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1197,
     "status": "ok",
     "timestamp": 1541580362058,
     "user": {
      "displayName": "Daniel McKee",
      "photoUrl": "",
      "userId": "05833574158187352909"
     },
     "user_tz": 360
    },
    "id": "qbcFiz0pI1yF",
    "outputId": "4b19ba28-1983-4ba5-c76d-58e1b04ed031",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "D = Discriminator().to(device)\n",
    "G = Generator(noise_dim=NOISE_DIM).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_optimizer = torch.optim.Adam(D.parameters(), lr=learning_rate, betas = (0.5, 0.999))\n",
    "G_optimizer = torch.optim.Adam(G.parameters(), lr=learning_rate, betas = (0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123257,
     "output_embedded_package_id": "19xasdXVLHHqm49kNhdVP-_6_HgusDIL6"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1586402,
     "status": "ok",
     "timestamp": 1541578057701,
     "user": {
      "displayName": "Daniel McKee",
      "photoUrl": "",
      "userId": "05833574158187352909"
     },
     "user_tz": 360
    },
    "id": "nVD3zfFnG6e0",
    "outputId": "3593a582-3369-4686-9fcb-6dc52d862db3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# original gan\n",
    "train(D, G, D_optimizer, G_optimizer, discriminator_loss, \n",
    "          generator_loss, num_epochs=NUM_EPOCHS, show_every=250,\n",
    "          train_loader=celeba_loader_train, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train LS-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator().to(device)\n",
    "G = Generator(noise_dim=NOISE_DIM).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_optimizer = torch.optim.Adam(D.parameters(), lr=learning_rate, betas = (0.5, 0.999))\n",
    "G_optimizer = torch.optim.Adam(G.parameters(), lr=learning_rate, betas = (0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls-gan\n",
    "train(D, G, D_optimizer, G_optimizer, ls_discriminator_loss, \n",
    "          ls_generator_loss, num_epochs=NUM_EPOCHS, show_every=200,\n",
    "          train_loader=celeba_loader_train, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
